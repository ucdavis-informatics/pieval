{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mongo DB connection Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and config\n",
    "import pandas as pd\n",
    "from pymongo import UpdateOne, MongoClient\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import funcy\n",
    "import json\n",
    "\n",
    "# siblings\n",
    "import data_loader # !symlink hack to make this work - ln -s ../app/data_loader.py! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mongo_client(mongo_connect_dict, tls_flag=True, tlsAllowInvalidCertificates=False):\n",
    "    return MongoClient(host=mongo_connect_dict['host'],\n",
    "                            port=int(mongo_connect_dict['port']),\n",
    "                            username=mongo_connect_dict['user'],\n",
    "                            password=mongo_connect_dict['pass'],\n",
    "                            authSource=mongo_connect_dict['auth_source'],\n",
    "                            tls=tls_flag,\n",
    "                            tlsAllowInvalidCertificates=tlsAllowInvalidCertificates)\n",
    "\n",
    "\n",
    "def print_collection_sizes(notes_db):\n",
    "    for coll_name in notes_db.list_collection_names():\n",
    "        if coll_name != 'system.views':\n",
    "            if coll_name.startswith('v_'):\n",
    "                print(f\"VIEW      : {coll_name}                has {notes_db[coll_name].count_documents({})} documents\")\n",
    "            else:\n",
    "                print(f\"COLLECTION: {coll_name}                has {notes_db[coll_name].estimated_document_count()} documents\")\n",
    "        else:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin', 'config', 'local', 'pv_db']\n",
      "Database already exists\n",
      "COLLECTION: projects                has 4 documents\n",
      "COLLECTION: users                has 2 documents\n",
      "COLLECTION: project_data                has 39 documents\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# creating the client\n",
    "local_connect_dict = {\n",
    "    \"host\":\"localhost\",\n",
    "    \"port\":27017,\n",
    "    \"user\":'',\n",
    "    \"pass\":'',\n",
    "    \"auth_source\":''\n",
    "}\n",
    "mongo_client = get_mongo_client(local_connect_dict, tls_flag=False, tlsAllowInvalidCertificates=True)\n",
    "\n",
    "\"\"\"\n",
    "Test client by reading out current database names\n",
    "\"\"\"\n",
    "print(mongo_client.list_database_names())\n",
    "if 'pv_db' in mongo_client.list_database_names():\n",
    "    print(\"Database already exists\")\n",
    "    pv_db = mongo_client['pv_db']\n",
    "    print(print_collection_sizes(pv_db))\n",
    "else:\n",
    "    print('Creating pv_db database')\n",
    "    pv_db = mongo_client['pv_db']\n",
    "    pv_db.create_collection('projects')\n",
    "    pv_db.create_collection('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[{'_id': 'awriedl', 'email': 'awriedl@ucdavis.edu', 'print_name': 'Bill', 'user_name': 'awriedl'}, {'_id': 'pieval', 'email': 'pieval@pieval.edu', 'print_name': 'pieval', 'user_name': 'pieval'}]\n"
     ]
    }
   ],
   "source": [
    "# user data\n",
    "pv_dl = data_loader.MongoDataLoader(local_connect_dict, 'pv_db','users','projects','project_data' )\n",
    "users = pv_dl.get_user_data()\n",
    "print(len(users))\n",
    "print(users[:5])\n",
    "with open('../example_database/users.json', 'w') as user_json_out:\n",
    "    json.dump(users, user_json_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cncr_hist_mc_demo', 'kappa_lambda_demo', 'movie_reviews_demo', 'image_demo'}\n",
      "4\n",
      "[{'_id': 'kappa_lambda_demo', 'class_list': None, 'data_type': 'text', 'project_description': 'DEMO PROJECT: Determining if monotypic/clonal plasma cell populations exist', 'project_mode': 'binary', 'project_name': 'kappa_lambda_demo', 'user_list': ['awriedl', 'pieval']}, {'_id': 'cncr_hist_mc_demo', 'class_list': ['carcinoma', 'adenocarcinoma', 'squamous cell', 'small cell', 'hodgkins lymphoma', 'myeloma', 'none'], 'data_type': 'text', 'project_description': 'DEMO PROJECT: Classifying cancer histology from pathology report text', 'project_mode': 'multiclass', 'project_name': 'cncr_hist_mc_demo', 'user_list': ['awriedl', 'pieval']}, {'_id': 'movie_reviews_demo', 'class_list': ['positive', 'bubbly', 'neutral', 'dismal', 'negative'], 'data_type': 'text', 'project_description': 'DEMO PROJECT: Classifying sentiment from movie reviews', 'project_mode': 'multiclass', 'project_name': 'movie_reviews_demo', 'user_list': ['awriedl', 'pieval']}, {'_id': 'image_demo', 'class_list': None, 'data_type': 'image', 'project_description': 'DEMO PROJECT: Classifying image contents', 'project_mode': 'binary', 'project_name': 'image_demo', 'user_list': ['pieval']}]\n"
     ]
    }
   ],
   "source": [
    "# project data\n",
    "pv_projects = pv_dl.get_projects()\n",
    "print(set([x['project_name'] for x in pv_projects]))\n",
    "print(len(pv_projects))\n",
    "print(pv_projects[:5])\n",
    "with open('../example_database/projects.json', 'w') as proj_json_out:\n",
    "    json.dump(pv_projects, proj_json_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kappa_lambda_demo', 'image_demo', 'cncr_hist_mc_demo', 'movie_reviews_demo', 'context_demo'}\n",
      "39\n",
      "[{'_id': 'movie_reviews_demo_0', 'data': 'Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss. A holiday to Burma with her sister seemed like a good idea to get away from it all, but when her passport was stolen in Rangoon, she could not leave the country with her sister, and was forced to stay back until she could get I.D. papers from the American embassy. To fill in a day before she could fly out, she took a trip into the countryside with a tour guide. \"I tried finding something in those stone statues, but nothing stirred in me. I was stone myself.\" <br /><br />Suddenly all hell broke loose and she was caught in a political revolt. Just when it looked like she had escaped and safely boarded a train, she saw her tour guide get beaten and shot. In a split second she decided to jump from the moving train and try to rescue him, with no thought of herself. Continually her life was in danger. <br /><br />Here is a woman who demonstrated spontaneous, selfless charity, risking her life to save another. Patricia Arquette is beautiful, and not just to look at; she has a beautiful heart. This is an unforgettable story. <br /><br />\"We are taught that suffering is the one promise that life always keeps.\"', 'data_ext': 'Based on an actual story, John Boorman shows the struggle of an American doctor, whose husband and son were murdered and she was continually plagued with her loss', 'example_id': 0, 'project_name': 'movie_reviews_demo', 'prompt': 'sentiment is positive', 'source_id': '0_positive'}, {'_id': 'movie_reviews_demo_1', 'data': \"I really like this show. It has drama, romance, and comedy all rolled into one. I am 28 and I am a married mother, so I can identify both with Lorelei's and Rory's experiences in the show. I have been watching mostly the repeats on the Family Channel lately, so I am not up-to-date on what is going on now. I think females would like this show more than males, but I know some men out there would enjoy it! I really like that is an hour long and not a half hour, as th hour seems to fly by when I am watching it! Give it a chance if you have never seen the show! I think Lorelei and Luke are my favorite characters on the show though, mainly because of the way they are with one another. How could you not see something was there (or take that long to see it I guess I should say)? <br /><br />Happy viewing!\", 'data_ext': 'I really like this show', 'example_id': 1, 'project_name': 'movie_reviews_demo', 'prompt': 'sentiment is positive', 'source_id': '2_positive'}, {'_id': 'movie_reviews_demo_2', 'data': \"Ouch! This one was a bit painful to sit through. It has a cute and amusing premise, but it all goes to hell from there. Matthew Modine is almost always pedestrian and annoying, and he does not disappoint in this one. Deborah Kara Unger and John Neville turned in surprisingly decent performances. Alan Bates and Jennifer Tilly, among others, played it way over the top. I know that's the way the parts were written, and it's hard to blame actors, when the script and director have them do such schlock. If you're going to have outrageous characters, that's OK, but you gotta have good material to make it work. It didn't here. Run away screaming from this movie if at all possible.\", 'data_ext': 'Ouch! This one was a bit painful to sit through', 'example_id': 2, 'project_name': 'movie_reviews_demo', 'prompt': 'sentiment is negative', 'source_id': '2_negative'}, {'_id': 'movie_reviews_demo_3', 'data': \"Of the Korean movies I've seen, only three had really stuck with me. The first is the excellent horror A Tale of Two Sisters. The second and third - and now fourth too - have all been Park Chan Wook's movies, namely Oldboy, Sympathy for Lady Vengeance), and now Thirst. <br /><br />Park kinda reminds me of Quentin Tarantino with his irreverence towards convention. All his movies are shocking, but not in a gratuitous sense. It's more like he shows us what we don't expect to see - typically situations that go radically against society's morals, like incest or a libidinous, blood-sucking, yet devout priest. He's also quite artistically-inclined with regards to cinematography, and his movies are among the more gorgeous that I've seen.<br /><br />Thirst is all that - being about said priest and the repressed, conscience-less woman he falls for - and more. It's horror, drama, and even comedy, as Park disarms his audience with many inappropriate yet humorous situations. As such, this might be his best work for me yet, since his other two movies that I've seen were lacking the humor element that would've made them more palatable for repeat viewings.\", 'data_ext': \"Of the Korean movies I've seen, only three had really stuck with me\", 'example_id': 3, 'project_name': 'movie_reviews_demo', 'prompt': 'sentiment is positive', 'source_id': '4_positive'}, {'_id': 'movie_reviews_demo_4', 'data': 'It\\'s a strange feeling to sit alone in a theater occupied by parents and their rollicking kids. I felt like instead of a movie ticket, I should have been given a NAMBLA membership.<br /><br />Based upon Thomas Rockwell\\'s respected Book, How To Eat Fried Worms starts like any children\\'s story: moving to a new town. The new kid, fifth grader Billy Forrester was once popular, but has to start anew. Making friends is never easy, especially when the only prospect is Poindexter Adam. Or Erica, who at 4 1/2 feet, is a giant.<br /><br />Further complicating things is Joe the bully. His freckled face and sleeveless shirts are daunting. He antagonizes kids with the Death Ring: a Crackerjack ring that is rumored to kill you if you\\'re punched with it. But not immediately. No, the death ring unleashes a poison that kills you in the eight grade.<br /><br />Joe and his axis of evil welcome Billy by smuggling a handful of slimy worms into his thermos. Once discovered, Billy plays it cool, swearing that he eats worms all the time. Then he throws them at Joe\\'s face. Ewww! To win them over, Billy reluctantly bets that he can eat 10 worms. Fried, boiled, marinated in hot sauce, squashed and spread on a peanut butter sandwich. Each meal is dubbed an exotic name like the \"Radioactive Slime Delight,\" in which the kids finally live out their dream of microwaving a living organism.<br /><br />If you\\'ve ever met me, you\\'ll know that I have an uncontrollably hearty laugh. I felt like a creep erupting at a toddler whining that his \"dilly dick\" hurts. But Fried Worms is wonderfully disgusting. Like a G-rated Farrelly brothers film, it is both vomitous and delightful.<br /><br />Writer/director Bob Dolman is also a savvy storyteller. To raise the stakes the worms must be consumed by 7 pm. In addition Billy holds a dark secret: he has an ultra-sensitive stomach.<br /><br />Dolman also has a keen sense of perspective. With such accuracy, he draws on children\\'s insecurities and tendency to exagger', 'data_ext': \"It's a strange feeling to sit alone in a theater occupied by parents and their rollicking kids\", 'example_id': 4, 'project_name': 'movie_reviews_demo', 'prompt': 'sentiment is positive', 'source_id': '3_positive'}]\n"
     ]
    }
   ],
   "source": [
    "# project data data\n",
    "pv_project_data = pv_dl.get_project_data()\n",
    "print(set([x['project_name'] for x in pv_project_data]))\n",
    "print(len(pv_project_data))\n",
    "print(pv_project_data[:5])\n",
    "with open('../example_database/project_data.json', 'w') as proj_data_json_out:\n",
    "    json.dump(pv_project_data, proj_data_json_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Data and Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_data = pv_dl.get_project_data(project_name='cncr_hist_mc_demo')\n",
    "print(len(prj_data))\n",
    "\n",
    "\n",
    "# convert raw project data (maybe annots maybe not) into dataframe\n",
    "prj_data_df = pd.DataFrame(prj_data)\n",
    "print(prj_data_df.shape)\n",
    "display(prj_data_df)\n",
    "\n",
    "if 'annots' in prj_data_df.columns:\n",
    "    prj_data_annots = prj_data_df.explode('annots').reset_index(drop=True)\n",
    "    print(prj_data_annots.shape)\n",
    "    display(prj_data_annots)\n",
    "    prj_data_annots_final = prj_data_annots.join(prj_data_annots['annots'].apply(pd.Series))\n",
    "    print(prj_data_annots_final.shape)\n",
    "    display(prj_data_annots_final)\n",
    "else:\n",
    "    print(\"No annots for this project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding/Deleting Annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an annotation\n",
    "# step 1 - obtain the example\n",
    "one_example = prj_data[1]\n",
    "cur_dt = datetime.now()\n",
    "cur_dt = cur_dt.replace(microsecond=0)\n",
    "# step 2 - see if any prior annotations exists\n",
    "if 'annots' in one_example:\n",
    "    print(\"There are prior annotations!\")\n",
    "    # in this case grab the current annot array\n",
    "    annot_array = one_example['annots']\n",
    "    max_annot_id = max([x['annot_id'] for x in annot_array])\n",
    "    one_annot = {\n",
    "        'annot_id':max_annot_id+1,\n",
    "        'response_time':cur_dt,\n",
    "        'user_name':'pieval_test',\n",
    "        'user_ip':'127.0.0.1',\n",
    "        'response':'testing',\n",
    "        'context_viewed':'yes'\n",
    "    }\n",
    "    annot_array.append(one_annot)\n",
    "else:\n",
    "    print(\"There are no prior annotations\")\n",
    "    # in this case create a new annot array\n",
    "    one_annot = {\n",
    "        'annot_id':0,\n",
    "        'response_time':cur_dt,\n",
    "        'user_name':'pieval_test',\n",
    "        'user_ip':'127.0.0.1',\n",
    "        'response':'testing',\n",
    "        'context_viewed':'yes'\n",
    "    }    \n",
    "    annot_array = [one_annot]\n",
    "\n",
    "extra_feature_dict = {'annots':annot_array}\n",
    "pv_dl.update_example(one_example, extra_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deleting an annotation\n",
    "annot_id_to_delete = 2\n",
    "one_example = prj_data[0]\n",
    "if 'annots' in one_example:\n",
    "    print(f\"There are prior annotations! - deleting annot with id = {annot_id_to_delete}\")\n",
    "    annot_array = one_example['annots']\n",
    "    new_annot_array = [x for x in annot_array if x['annot_id'] != annot_id_to_delete]\n",
    "else:\n",
    "    print(\"There are no prior annotations - Nothing to delete!\")\n",
    "\n",
    "print(\"OG annot array\")\n",
    "print(annot_array)\n",
    "print(\"updated annot array\")\n",
    "print(new_annot_array)\n",
    "\n",
    "# now set the version in mongo to the updated annot array\n",
    "extra_feature_dict = {'annots':new_annot_array}\n",
    "pv_dl.saveAnnot(one_example, extra_feature_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/reformatting Example data into JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_classes_df = pd.read_csv('../example_database/project_classes.csv')\n",
    "proj_users = pd.read_csv('../example_database/project_users.csv')\n",
    "proj_df = pd.read_csv('../example_database/projects.csv')\n",
    "\n",
    "# project data - the documents\n",
    "proj_data_df = pd.read_csv('../example_database/project_data.csv')\n",
    "# user information\n",
    "user_df = pd.read_csv('../example_database/user_details.csv')\n",
    "\n",
    "# these data WONT be loaded in to the example database - this structure will be considered completely legacy\n",
    "annot_df = pd.read_csv('../example_database/annotation_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging project data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_users_grp = (proj_users.groupby('project_name')\n",
    "                  .agg(\n",
    "                      user_list=('user_name',lambda x:list(x))\n",
    "                      )\n",
    "                    .reset_index()\n",
    "                )\n",
    "\n",
    "proj_classes_grp = (proj_classes_df.groupby('project_name')\n",
    "                  .agg(\n",
    "                      class_list=('class',lambda x:list(x))\n",
    "                      )\n",
    "                    .reset_index()\n",
    "                )\n",
    "\n",
    "proj_final_df = pd.merge(proj_df, proj_users_grp, how='left', on='project_name')\n",
    "proj_final_df = pd.merge(proj_final_df, proj_classes_grp, how='left', on='project_name')\n",
    "\n",
    "proj_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write project data to mongo\n",
    "proj_dict_list = proj_final_df.to_dict(orient='records')\n",
    "for one_obj in proj_dict_list:\n",
    "    for k,v in one_obj.items():\n",
    "        if isinstance(v, (pd._libs.tslibs.nattype.NaTType)):\n",
    "            one_obj[k] = None\n",
    "        if (isinstance(v, float) and np.isnan(v)):\n",
    "            one_obj[k] = None\n",
    "        if isinstance(v, np.ndarray):\n",
    "            one_obj[k] = v.tolist()\n",
    "\n",
    "proj_upserts = [UpdateOne({\"_id\": str(x.get('project_name'))},\n",
    "                    {\"$set\": x},\n",
    "                    upsert=True) for x in proj_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_res = pv_db['projects'].bulk_write(proj_upserts)\n",
    "bulk_api_result_dict = bulk_res.bulk_api_result\n",
    "bulk_api_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_data_df[\"_id\"] = proj_data_df['project_name'] + '_' + proj_data_df['example_id'].astype(str)\n",
    "proj_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_data_df['_id'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write project data to mongo\n",
    "proj_data_dict_list = proj_data_df.to_dict(orient='records')\n",
    "for one_obj in proj_data_dict_list:\n",
    "    for k,v in one_obj.items():\n",
    "        if isinstance(v, (pd._libs.tslibs.nattype.NaTType)):\n",
    "            one_obj[k] = None\n",
    "        if (isinstance(v, float) and np.isnan(v)):\n",
    "            one_obj[k] = None\n",
    "        if isinstance(v, np.ndarray):\n",
    "            one_obj[k] = v.tolist()\n",
    "\n",
    "proj_data_upserts = [UpdateOne({\"_id\": str(x.get('_id'))},\n",
    "                    {\"$set\": x},\n",
    "                    upsert=True) for x in proj_data_dict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_res = pv_db['project_data'].bulk_write(proj_data_upserts)\n",
    "bulk_api_result_dict = bulk_res.bulk_api_result\n",
    "bulk_api_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df[\"_id\"] = user_df['user_name']\n",
    "user_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write project data to mongo\n",
    "user_dict_list = user_df.to_dict(orient='records')\n",
    "for one_obj in user_dict_list:\n",
    "    for k,v in one_obj.items():\n",
    "        if isinstance(v, (pd._libs.tslibs.nattype.NaTType)):\n",
    "            one_obj[k] = None\n",
    "        if (isinstance(v, float) and np.isnan(v)):\n",
    "            one_obj[k] = None\n",
    "        if isinstance(v, np.ndarray):\n",
    "            one_obj[k] = v.tolist()\n",
    "\n",
    "user_upserts = [UpdateOne({\"_id\": str(x.get('_id'))},\n",
    "                    {\"$set\": x},\n",
    "                    upsert=True) for x in user_dict_list]\n",
    "user_upserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_res = pv_db['users'].bulk_write(user_upserts)\n",
    "bulk_api_result_dict = bulk_res.bulk_api_result\n",
    "bulk_api_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Data\n",
    "\n",
    "> NOTE!  In the mongo version of this project, there will not be a seperate annoation collection.  We will simply update the original documents in project_data with additional k:v pairs resulting from the annotation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
